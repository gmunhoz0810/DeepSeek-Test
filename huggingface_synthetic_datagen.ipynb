{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic User Data Generator\n",
    "A simple toolkit for generating realistic but completely fictional user profiles using a language model. \n",
    "\n",
    "These profiles can be used for testing, demos, or filling sample databases without exposing real user data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Class Features\n",
    "\n",
    "- Generate any number of synthetic user profiles with customizable attributes\n",
    "\n",
    "- Uses example profiles as templates to ensure consistent formatting\n",
    "\n",
    "- Filter by demographics, location, industry, and more\n",
    "\n",
    "- Export data as CSV or JSON\n",
    "\n",
    "- Leverages GPU acceleration when available for faster generation\n",
    "\n",
    "- Creates completely fictional data that looks realistic but doesn't represent real individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import re\n",
    "import os\n",
    "\n",
    "# setup basic logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler('generator.log')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def generate_synthetic_data(\n",
    "    num_records=10,\n",
    "    model_name=\"HuggingFaceTB/SmolLM2-1.7B-Instruct\",\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=3000,\n",
    "    output_file=\"synthetic_users.csv\",\n",
    "    example_data=None,\n",
    "    save_raw=True,\n",
    "    # guidance params\n",
    "    countries=None,\n",
    "    age_range=None,\n",
    "    states=None,\n",
    "    occupations=None,\n",
    "    industries=None,\n",
    "    email_domains=None,\n",
    "    time_period=None,\n",
    "    gender=None,\n",
    "    guidance_notes=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate synthetic data based on example structure with optional guidance parameters.\n",
    "    \"\"\"\n",
    "    # fallback to defaults if no examples given\n",
    "    if example_data is None:\n",
    "        example_data = [\n",
    "            {\n",
    "                \"ID\": 1,\n",
    "                \"Name\": \"Melissa Thornton\",\n",
    "                \"Age\": 34,\n",
    "                \"Email\": \"m.thornton83@fastmail.net\",\n",
    "                \"Phone\": \"507-382-9155\",\n",
    "                \"Address\": \"726 Willow Lane\",\n",
    "                \"City\": \"Rochester\",\n",
    "                \"State\": \"MN\",\n",
    "                \"Country\": \"United States\",\n",
    "                \"ZIP\": \"55901\",\n",
    "                \"Occupation\": \"Dental Hygienist\",\n",
    "                \"Account_Created\": \"2022-03-17\",\n",
    "                \"Last_Login\": \"2025-02-15\"\n",
    "            },\n",
    "            {\n",
    "                \"ID\": 2,\n",
    "                \"Name\": \"Jamal Washington\",\n",
    "                \"Age\": 42,\n",
    "                \"Email\": \"jwash_business@gmail.com\",\n",
    "                \"Phone\": \"213-555-8071\",\n",
    "                \"Address\": \"1840 Crenshaw Blvd\",\n",
    "                \"City\": \"Los Angeles\",\n",
    "                \"State\": \"CA\",\n",
    "                \"Country\": \"United States\",\n",
    "                \"ZIP\": \"90008\",\n",
    "                \"Occupation\": \"Marketing Director\",\n",
    "                \"Account_Created\": \"2021-06-04\",\n",
    "                \"Last_Login\": \"2025-02-25\"\n",
    "            },\n",
    "            {\n",
    "                \"ID\": 3,\n",
    "                \"Name\": \"Mei-Ling Chen\",\n",
    "                \"Age\": 27,\n",
    "                \"Email\": \"meiling.chen@outlook.com\",\n",
    "                \"Phone\": \"415-222-3644\",\n",
    "                \"Address\": \"892 Stockton Street\",\n",
    "                \"City\": \"San Francisco\",\n",
    "                \"State\": \"CA\",\n",
    "                \"Country\": \"United States\",\n",
    "                \"ZIP\": \"94108\",\n",
    "                \"Occupation\": \"Software Engineer\",\n",
    "                \"Account_Created\": \"2023-08-15\",\n",
    "                \"Last_Login\": \"2025-03-01\"\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    # count our examples\n",
    "    num_examples = len(example_data)\n",
    "    \n",
    "    # adjust requested records to include examples\n",
    "    total_records = num_records + num_examples\n",
    "    \n",
    "    # figure out where to start the IDs\n",
    "    next_id = max([ex[\"ID\"] for ex in example_data]) + 1\n",
    "    \n",
    "    logger.info(f\"Loading model: {model_name}\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "    \n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "        logger.info(\"Model loaded successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load model: {e}\")\n",
    "        raise\n",
    "\n",
    "    # format examples for the prompt\n",
    "    examples_formatted = \"\"\n",
    "    for example in example_data:\n",
    "        examples_formatted += \"STARTRECORD\\n\"\n",
    "        for key, value in example.items():\n",
    "            examples_formatted += f\"{key}: {value}\\n\"\n",
    "        examples_formatted += \"ENDRECORD\\n\\n\"\n",
    "    \n",
    "    # build up the guidance text based on params\n",
    "    guidance_instructions = []\n",
    "    \n",
    "    if countries:\n",
    "        if isinstance(countries, list):\n",
    "            countries_text = \", \".join(countries)\n",
    "        else:\n",
    "            countries_text = countries\n",
    "        guidance_instructions.append(f\"- Only generate profiles from these countries/regions: {countries_text}\")\n",
    "    \n",
    "    if age_range:\n",
    "        if isinstance(age_range, list) and len(age_range) == 2:\n",
    "            age_text = f\"between {age_range[0]} and {age_range[1]}\"\n",
    "        else:\n",
    "            age_text = str(age_range)\n",
    "        guidance_instructions.append(f\"- Age should be {age_text}\")\n",
    "    \n",
    "    if states:\n",
    "        if isinstance(states, list):\n",
    "            states_text = \", \".join(states)\n",
    "        else:\n",
    "            states_text = states\n",
    "        guidance_instructions.append(f\"- Only use these states/provinces: {states_text}\")\n",
    "    \n",
    "    if occupations:\n",
    "        if isinstance(occupations, list):\n",
    "            occupations_text = \", \".join(occupations)\n",
    "        else:\n",
    "            occupations_text = occupations\n",
    "        guidance_instructions.append(f\"- Use these occupations: {occupations_text}\")\n",
    "    \n",
    "    if industries:\n",
    "        if isinstance(industries, list):\n",
    "            industries_text = \", \".join(industries)\n",
    "        else:\n",
    "            industries_text = industries\n",
    "        guidance_instructions.append(f\"- Focus on these industries: {industries_text}\")\n",
    "    \n",
    "    if email_domains:\n",
    "        if isinstance(email_domains, list):\n",
    "            domains_text = \", \".join(email_domains)\n",
    "        else:\n",
    "            domains_text = email_domains\n",
    "        guidance_instructions.append(f\"- Use these email domains: {domains_text}\")\n",
    "    \n",
    "    if time_period:\n",
    "        guidance_instructions.append(f\"- All dates should be within: {time_period}\")\n",
    "    \n",
    "    if gender:\n",
    "        if isinstance(gender, list):\n",
    "            gender_text = \", \".join(gender)\n",
    "        else:\n",
    "            gender_text = gender\n",
    "        guidance_instructions.append(f\"- Only include {gender_text} individuals\")\n",
    "    \n",
    "    if guidance_notes:\n",
    "        guidance_instructions.append(f\"- Additional guidance: {guidance_notes}\")\n",
    "    \n",
    "    # default to something if nothing specified\n",
    "    if not guidance_instructions:\n",
    "        guidance_instructions.append(\"- Include diverse demographics, backgrounds, locations, and occupations\")\n",
    "    \n",
    "    # stick it all together\n",
    "    guidance_text = \"\\n\".join(guidance_instructions)\n",
    "    \n",
    "    prompt = f\"\"\"Generate {total_records} completely fictional user profiles.\n",
    "\n",
    "Here are some example profiles in the required format:\n",
    "\n",
    "{examples_formatted}\n",
    "\n",
    "Rules:\n",
    "1. Generate exactly {total_records} total records\n",
    "2. Use the EXACT same field names and format as the examples\n",
    "3. Include the initial sample examples in the answer.\n",
    "3. Each profile must be wrapped with STARTRECORD and ENDRECORD delimiters\n",
    "4. Make the data realistic but entirely fictional\n",
    "5. Make sure some fields such as address, phone number, email address, etc, are all unique. We should not have this sort of data repeated between individuals.\n",
    "\n",
    "Specific guidance for these profiles:\n",
    "{guidance_text}\n",
    "\n",
    "ONLY generate profiles with the STARTRECORD/ENDRECORD format. No other text.\"\"\"\n",
    "\n",
    "    logger.debug(f\"Prompt: {prompt}\")\n",
    "\n",
    "    # setup for the model\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    \n",
    "    logger.info(f\"Generating {total_records} records (including {num_examples} examples)\")\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            attention_mask=inputs.attention_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=0.95,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # get what the model output\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = output_text.split(input_text)[-1].strip()\n",
    "    \n",
    "    # raw output for debugging\n",
    "    if save_raw:\n",
    "        with open(\"raw_model_output.txt\", \"w\") as f:\n",
    "            f.write(response)\n",
    "        logger.info(\"Raw model output saved to raw_model_output.txt\")\n",
    "    \n",
    "    # parse out the records from the response\n",
    "    records = []\n",
    "    pattern = r\"STARTRECORD(.*?)ENDRECORD\"\n",
    "    matches = re.findall(pattern, response, re.DOTALL)\n",
    "    \n",
    "    logger.info(f\"Found {len(matches)} record blocks in response\")\n",
    "    \n",
    "    for i, match in enumerate(matches):\n",
    "        record = {}\n",
    "        \n",
    "        # split into lines and extract field:value pairs\n",
    "        lines = match.strip().split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if ':' in line:\n",
    "                key, value = line.split(':', 1)\n",
    "                key = key.strip()\n",
    "                value = value.strip()\n",
    "                record[key] = value\n",
    "        \n",
    "        if record:\n",
    "            records.append(record)\n",
    "    \n",
    "    logger.info(f\"Final record count: {len(records)}\")\n",
    "    \n",
    "    # save records to dataframe\n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # save to disk if needed\n",
    "    if output_file:\n",
    "        output_dir = os.path.dirname(output_file)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "        if output_file.endswith('.csv'):\n",
    "            df.to_csv(output_file, index=False)\n",
    "        elif output_file.endswith('.json'):\n",
    "            df.to_json(output_file, orient='records', indent=2)\n",
    "        else:\n",
    "            df.to_csv(output_file, index=False)\n",
    "            \n",
    "        logger.info(f\"Saved {len(df)} records to {output_file}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 04:46:49,783 - INFO - Loading model: HuggingFaceTB/SmolLM2-1.7B-Instruct\n",
      "2025-03-04 04:46:49,784 - INFO - Using device: cpu\n",
      "2025-03-04 04:46:53,071 - INFO - Model loaded successfully\n",
      "2025-03-04 04:46:53,072 - INFO - Generating 13 records (including 3 examples)\n",
      "2025-03-04 04:50:49,605 - INFO - Raw model output saved to raw_model_output.txt\n",
      "2025-03-04 04:50:49,607 - INFO - Found 18 record blocks in response\n",
      "2025-03-04 04:50:49,608 - INFO - Final record count: 16\n",
      "2025-03-04 04:50:49,612 - INFO - Saved 16 records to tech_professionals.csv\n"
     ]
    }
   ],
   "source": [
    "tech_professionals_df = generate_synthetic_data(\n",
    "    num_records=10, \n",
    "    states=[\"CA\", \"NY\"],\n",
    "    industries=\"Technology\",\n",
    "    occupations=[\"Software Engineer\", \"Data Scientist\", \"Product Manager\", \"UX Designer\"],\n",
    "    age_range=[25, 45],\n",
    "    email_domains=[\"gmail.com\", \"outlook.com\", \"icloud.com\", \"protonmail.com\"],\n",
    "    time_period=\"2020-present\",\n",
    "    output_file=\"tech_professionals.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
